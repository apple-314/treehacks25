\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{anil2018large}
Rohan Anil, Gabriel Pereyra, Alexandre Passos, Robert Ormandi, George~E Dahl,
  and Geoffrey~E Hinton.
\newblock Large scale distributed neural network training through online
  distillation.
\newblock {\em arXiv preprint arXiv:1804.03235}, 2018.

\bibitem{asano2019self}
Yuki~Markus Asano, Christian Rupprecht, and Andrea Vedaldi.
\newblock Self-labelling via simultaneous clustering and representation
  learning.
\newblock In {\em ICLR}, 2020.

\bibitem{assran2020recovering}
Mahmoud Assran, Nicolas Ballas, Lluis Castrejon, and Michael Rabbat.
\newblock Recovering petaflops in contrastive semi-supervised learning of
  visual representations.
\newblock {\em preprint arXiv:2006.10803}, 2020.

\bibitem{bahdanau2014neural}
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio.
\newblock Neural machine translation by jointly learning to align and
  translate.
\newblock {\em preprint arXiv:1409.0473}, 2014.

\bibitem{berman2019multigrain}
Maxim Berman, Herv{\'e} J{\'e}gou, Vedaldi Andrea, Iasonas Kokkinos, and
  Matthijs Douze.
\newblock {{MultiGrain}: a unified image embedding for classes and instances}.
\newblock {\em arXiv preprint arXiv:1902.05509}, 2019.

\bibitem{bojanowski2017unsupervised}
Piotr Bojanowski and Armand Joulin.
\newblock Unsupervised learning by predicting noise.
\newblock In {\em ICML}, 2017.

\bibitem{bucilua2006model}
Cristian Buciluǎ, Rich Caruana, and Alexandru Niculescu-Mizil.
\newblock Model compression.
\newblock In {\em SIGKDD}, 2006.

\bibitem{caron2018deep}
Mathilde Caron, Piotr Bojanowski, Armand Joulin, and Matthijs Douze.
\newblock Deep clustering for unsupervised learning of visual features.
\newblock In {\em ECCV}, 2018.

\bibitem{caron2019unsupervised}
Mathilde Caron, Piotr Bojanowski, Julien Mairal, and Armand Joulin.
\newblock Unsupervised pre-training of image features on non-curated data.
\newblock In {\em ICCV}, 2019.

\bibitem{caron2020unsupervised}
Mathilde Caron, Ishan Misra, Julien Mairal, Priya Goyal, Piotr Bojanowski, and
  Armand Joulin.
\newblock Unsupervised learning of visual features by contrasting cluster
  assignments.
\newblock In {\em NeurIPS}, 2020.

\bibitem{chen2018best}
Mia~Xu Chen, Orhan Firat, Ankur Bapna, Melvin Johnson, Wolfgang Macherey,
  George Foster, Llion Jones, Niki Parmar, Mike Schuster, Zhifeng Chen, et~al.
\newblock The best of both worlds: Combining recent advances in neural machine
  translation.
\newblock {\em preprint arXiv:1804.09849}, 2018.

\bibitem{chen2020simple}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock {\em preprint arXiv:2002.05709}, 2020.

\bibitem{chen2020big}
Ting Chen, Simon Kornblith, Kevin Swersky, Mohammad Norouzi, and Geoffrey
  Hinton.
\newblock Big self-supervised models are strong semi-supervised learners.
\newblock In {\em NeurIPS}, 2020.

\bibitem{chen2020unsupervised}
Weijie Chen, Shiliang Pu, Di Xie, Shicai Yang, Yilu Guo, and Luojun Lin.
\newblock Unsupervised image classification for deep representation learning.
\newblock {\em arXiv preprint arXiv:2006.11480}, 2020.

\bibitem{chen2020improved}
Xinlei Chen, Haoqi Fan, Ross Girshick, and Kaiming He.
\newblock Improved baselines with momentum contrastive learning.
\newblock {\em preprint arXiv:2003.04297}, 2020.

\bibitem{chen2020exploring}
Xinlei Chen and Kaiming He.
\newblock Exploring simple siamese representation learning.
\newblock {\em preprint arXiv:2011.10566}, 2020.

\bibitem{cuturi2013sinkhorn}
Marco Cuturi.
\newblock Sinkhorn distances: Lightspeed computation of optimal transport.
\newblock In {\em NeurIPS}, 2013.

\bibitem{devlin2018bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock {\em preprint arXiv:1810.04805}, 2018.

\bibitem{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock {\em preprint arXiv:2010.11929}, 2020.

\bibitem{dosovitskiy2016discriminative}
Alexey Dosovitskiy, Philipp Fischer, Jost~Tobias Springenberg, Martin
  Riedmiller, and Thomas Brox.
\newblock Discriminative unsupervised feature learning with exemplar
  convolutional neural networks.
\newblock {\em TPAMI}, 2016.

\bibitem{douze2009evaluation}
Matthijs Douze, Herv{\'e} J{\'e}gou, Harsimrat Sandhawalia, Laurent Amsaleg,
  and Cordelia Schmid.
\newblock Evaluation of gist descriptors for web-scale image search.
\newblock In {\em CIVR}, 2009.

\bibitem{el2021training}
Alaaeldin El-Nouby, Natalia Neverova, Ivan Laptev, and Herv{\'e} J{\'e}gou.
\newblock Training vision transformers for image retrieval.
\newblock {\em preprint arXiv:2102.05644}, 2021.

\bibitem{ermolov2020whitening}
Aleksandr Ermolov, Aliaksandr Siarohin, Enver Sangineto, and Nicu Sebe.
\newblock Whitening for self-supervised representation learning.
\newblock {\em preprint arXiv:2007.06346}, 2020.

\bibitem{everingham2010pascal}
Mark Everingham, Luc Van~Gool, Christopher~KI Williams, John Winn, and Andrew
  Zisserman.
\newblock The pascal visual object classes (voc) challenge.
\newblock {\em IJCV}, 2010.

\bibitem{fang2021seed}
Zhiyuan Fang, Jianfeng Wang, Lijuan Wang, Lei Zhang, Yezhou Yang, and Zicheng
  Liu.
\newblock Seed: Self-supervised distillation for visual representation.
\newblock 2021.

\bibitem{gidaris2020learning}
Spyros Gidaris, Andrei Bursuc, Nikos Komodakis, Patrick P{\'e}rez, and Matthieu
  Cord.
\newblock Learning representations by predicting bags of visual words.
\newblock In {\em CVPR}, 2020.

\bibitem{gidaris2020obow}
Spyros Gidaris, Andrei Bursuc, Gilles Puy, Nikos Komodakis, Matthieu Cord, and
  Patrick P{\'e}rez.
\newblock Online bag-of-visual-words generation for unsupervised representation
  learning.
\newblock {\em arXiv preprint arXiv:2012.11552}, 2020.

\bibitem{goyal2021self}
Priya Goyal, Mathilde Caron, Benjamin Lefaudeux, Min Xu, Pengchao Wang, Vivek
  Pai, Mannat Singh, Vitaliy Liptchinsky, Ishan Misra, Armand Joulin, et~al.
\newblock Self-supervised pretraining of visual features in the wild.
\newblock {\em preprint arXiv:2103.01988}, 2021.

\bibitem{goyal2017accurate}
Priya Goyal, Piotr Doll{\'a}r, Ross Girshick, Pieter Noordhuis, Lukasz
  Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, and Kaiming He.
\newblock Accurate, large minibatch sgd: Training imagenet in 1 hour.
\newblock {\em preprint arXiv:1706.02677}, 2017.

\bibitem{grill2020bootstrap}
Jean-Bastien Grill, Florian Strub, Florent Altch{\'e}, Corentin Tallec,
  Pierre~H Richemond, Elena Buchatskaya, Carl Doersch, Bernardo~Avila Pires,
  Zhaohan~Daniel Guo, Mohammad~Gheshlaghi Azar, Bilal Piot, Koray Kavukcuoglu,
  Rémi Munos, and Michal Valko.
\newblock Bootstrap your own latent: A new approach to self-supervised
  learning.
\newblock In {\em NeurIPS}, 2020.

\bibitem{gur2020visualization}
Shir Gur, Ameen Ali, and Lior Wolf.
\newblock Visualization of supervised and self-supervised neural networks via
  attribution guided factorization.
\newblock {\em preprint arXiv:2012.02166}, 2020.

\bibitem{gutmann2010noise}
Michael Gutmann and Aapo Hyv{\"a}rinen.
\newblock Noise-contrastive estimation: A new estimation principle for
  unnormalized statistical models.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, 2010.

\bibitem{he2020momentum}
Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock In {\em CVPR}, 2020.

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em CVPR}, 2016.

\bibitem{hinton2015distilling}
Geoffrey Hinton, Oriol Vinyals, and Jeff Dean.
\newblock Distilling the knowledge in a neural network.
\newblock {\em preprint arXiv:1503.02531}, 2015.

\bibitem{huang2019unsupervised}
Jiabo Huang, Qi Dong, Shaogang Gong, and Xiatian Zhu.
\newblock Unsupervised deep learning by neighbourhood discovery.
\newblock In {\em ICML}, 2019.

\bibitem{jabri2020space}
Allan Jabri, Andrew Owens, and Alexei~A Efros.
\newblock Space-time correspondence as a contrastive random walk.
\newblock 2020.

\bibitem{jean2014using}
S{\'e}bastien Jean, Kyunghyun Cho, Roland Memisevic, and Yoshua Bengio.
\newblock On using very large target vocabulary for neural machine translation.
\newblock {\em preprint arXiv:1412.2007}, 2014.

\bibitem{klein2017opennmt}
Guillaume Klein, Yoon Kim, Yuntian Deng, Jean Senellart, and Alexander~M Rush.
\newblock Opennmt: Open-source toolkit for neural machine translation.
\newblock {\em preprint arXiv:1701.02810}, 2017.

\bibitem{lai2020mast}
Zihang Lai, Erika Lu, and Weidi Xie.
\newblock Mast: A memory-augmented self-supervised tracker.
\newblock In {\em CVPR}, 2020.

\bibitem{lee2013pseudo}
Dong-Hyun Lee et~al.
\newblock Pseudo-label: The simple and efficient semi-supervised learning
  method for deep neural networks.
\newblock In {\em Workshop on challenges in representation learning, ICML},
  2013.

\bibitem{junnan2021prototypical}
Junnan Li, Pan Zhou, Caiming Xiong, and Steven~C.H. Hoi.
\newblock Prototypical contrastive learning of unsupervised representations.
\newblock {\em ICLR}, 2021.

\bibitem{loshchilov2016sgdr}
Ilya Loshchilov and Frank Hutter.
\newblock Sgdr: Stochastic gradient descent with warm restarts.
\newblock {\em preprint arXiv:1608.03983}, 2016.

\bibitem{loshchilov2018fixing}
Ilya Loshchilov and Frank Hutter.
\newblock Fixing weight decay regularization in adam.
\newblock 2018.

\bibitem{mairal2019cyanure}
Julien Mairal.
\newblock Cyanure: An open-source toolbox for empirical risk minimization for
  python, c++, and soon more.
\newblock {\em preprint arXiv:1912.08165}, 2019.

\bibitem{nilsback2008automated}
Maria-Elena Nilsback and Andrew Zisserman.
\newblock Automated flower classification over a large number of classes.
\newblock In {\em 2008 Sixth Indian Conference on Computer Vision, Graphics \&
  Image Processing}, 2008.

\bibitem{noroozi2018boosting}
Mehdi Noroozi, Ananth Vinjimoor, Paolo Favaro, and Hamed Pirsiavash.
\newblock Boosting self-supervised learning via knowledge transfer.
\newblock In {\em CVPR}, 2018.

\bibitem{oh2019video}
Seoung~Wug Oh, Joon-Young Lee, Ning Xu, and Seon~Joo Kim.
\newblock Video object segmentation using space-time memory networks.
\newblock In {\em ICCV}, 2019.

\bibitem{pham2020meta}
Hieu Pham, Qizhe Xie, Zihang Dai, and Quoc~V Le.
\newblock Meta pseudo labels.
\newblock {\em preprint arXiv:2003.10580}, 2020.

\bibitem{philbin2008lost}
James Philbin, Ondrej Chum, Michael Isard, Josef Sivic, and Andrew Zisserman.
\newblock Lost in quantization: Improving particular object retrieval in large
  scale image databases.
\newblock In {\em CVPR}, 2008.

\bibitem{polyak1992acceleration}
Boris~T Polyak and Anatoli~B Juditsky.
\newblock Acceleration of stochastic approximation by averaging.
\newblock {\em SIAM journal on control and optimization}, 30(4):838--855, 1992.

\bibitem{pont20172017}
Jordi Pont-Tuset, Federico Perazzi, Sergi Caelles, Pablo Arbel{\'a}ez, Alex
  Sorkine-Hornung, and Luc Van~Gool.
\newblock The 2017 davis challenge on video object segmentation.
\newblock {\em preprint arXiv:1704.00675}, 2017.

\bibitem{radenovic2018revisiting}
Filip Radenovi{\'c}, Ahmet Iscen, Giorgos Tolias, Yannis Avrithis, and
  Ond{\v{r}}ej Chum.
\newblock Revisiting oxford and paris: Large-scale image retrieval
  benchmarking.
\newblock 2018.

\bibitem{radenovic2018fine}
Filip Radenovi{\'c}, Giorgos Tolias, and Ond{\v{r}}ej Chum.
\newblock Fine-tuning cnn image retrieval with no human annotation.
\newblock {\em IEEE transactions on pattern analysis and machine intelligence},
  2018.

\bibitem{radford2019language}
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
  Sutskever.
\newblock Language models are unsupervised multitask learners.

\bibitem{radosavovic2020designing}
Ilija Radosavovic, Raj~Prateek Kosaraju, Ross Girshick, Kaiming He, and Piotr
  Doll{\'a}r.
\newblock Designing network design spaces.
\newblock In {\em CVPR}, 2020.

\bibitem{revaud2019learning}
Jerome Revaud, Jon Almaz{\'a}n, Rafael~S Rezende, and Cesar Roberto~de Souza.
\newblock Learning with average precision: Training image retrieval with a
  listwise loss.
\newblock In {\em ICCV}, 2019.

\bibitem{richemond2020byol}
Pierre~H Richemond, Jean-Bastien Grill, Florent Altch{\'e}, Corentin Tallec,
  Florian Strub, Andrew Brock, Samuel Smith, Soham De, Razvan Pascanu, Bilal
  Piot, et~al.
\newblock Byol works even without batch statistics.
\newblock {\em preprint arXiv:2010.10241}, 2020.

\bibitem{ruppert1988efficient}
David Ruppert.
\newblock Efficient estimations from a slowly convergent robbins-monro process.
\newblock Technical report, 1988.

\bibitem{russakovsky2015imagenet}
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
  Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander~C
  Berg, and Li Fei-Fei.
\newblock Imagenet large scale visual recognition challenge.
\newblock {\em IJCV}, 2015.

\bibitem{salimans2016weight}
Tim Salimans and Diederik~P Kingma.
\newblock Weight normalization: A simple reparameterization to accelerate
  training of deep neural networks.
\newblock {\em NeurIPS}, 2016.

\bibitem{sariyildiz2020concept}
Mert~Bulent Sariyildiz, Yannis Kalantidis, Diane Larlus, and Karteek Alahari.
\newblock Concept generalization in visual representation learning.
\newblock {\em arXiv preprint arXiv:2012.05649}, 2020.

\bibitem{shen2021s2}
Zhiqiang Shen, Zechun Liu, Jie Qin, Lei Huang, Kwang-Ting Cheng, and Marios
  Savvides.
\newblock S2-bnn: Bridging the gap between self-supervised real and 1-bit
  neural networks via guided distribution calibration.
\newblock {\em arXiv preprint arXiv:2102.08946}, 2021.

\bibitem{sohn2020fixmatch}
Kihyuk Sohn, David Berthelot, Chun-Liang Li, Zizhao Zhang, Nicholas Carlini,
  Ekin~D Cubuk, Alex Kurakin, Han Zhang, and Colin Raffel.
\newblock Fixmatch: Simplifying semi-supervised learning with consistency and
  confidence.
\newblock In {\em NeurIPS}, 2020.

\bibitem{tarvainen2017mean}
Antti Tarvainen and Harri Valpola.
\newblock Mean teachers are better role models: Weight-averaged consistency
  targets improve semi-supervised deep learning results.
\newblock {\em preprint arXiv:1703.01780}, 2017.

\bibitem{thomee2015yfcc100m}
Bart Thomee, David~A Shamma, Gerald Friedland, Benjamin Elizalde, Karl Ni,
  Douglas Poland, Damian Borth, and Li-Jia Li.
\newblock Yfcc100m: The new data in multimedia research.
\newblock {\em arXiv preprint arXiv:1503.01817}, 2015.

\bibitem{tian2020makes}
Yonglong Tian, Chen Sun, Ben Poole, Dilip Krishnan, Cordelia Schmid, and
  Phillip Isola.
\newblock What makes for good views for contrastive learning.
\newblock {\em NeurIPS}, 2020.

\bibitem{tolias2015particular}
Giorgos Tolias, Ronan Sicre, and Herv{\'e} J{\'e}gou.
\newblock Particular object retrieval with integral max-pooling of cnn
  activations.
\newblock {\em arXiv preprint arXiv:1511.05879}, 2015.

\bibitem{touvron2020training}
Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre
  Sablayrolles, and Herv{\'e} J{\'e}gou.
\newblock Training data-efficient image transformers \& distillation through
  attention.
\newblock {\em preprint arXiv:2012.12877}, 2020.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In {\em NeurIPS}, 2017.

\bibitem{wang2019learning}
Xiaolong Wang, Allan Jabri, and Alexei~A Efros.
\newblock Learning correspondence from the cycle-consistency of time.
\newblock In {\em CVPR}, 2019.

\bibitem{weyand2020google}
Tobias Weyand, Andre Araujo, Bingyi Cao, and Jack Sim.
\newblock Google landmarks dataset v2-a large-scale benchmark for
  instance-level recognition and retrieval.
\newblock 2020.

\bibitem{wu2018unsupervised}
Zhirong Wu, Yuanjun Xiong, Stella~X Yu, and Dahua Lin.
\newblock Unsupervised feature learning via non-parametric instance
  discrimination.
\newblock In {\em CVPR}, 2018.

\bibitem{xie2016unsupervised}
Junyuan Xie, Ross Girshick, and Ali Farhadi.
\newblock Unsupervised deep embedding for clustering analysis.
\newblock In {\em ICML}, 2016.

\bibitem{xie2020unsupervised}
Qizhe Xie, Zihang~Dai Dai, Eduard Hovy, Minh-Thang Luong, and Quoc~V. Le.
\newblock Unsupervised data augmentation for consistency training.
\newblock {\em preprint arXiv:1904.12848}, 2020.

\bibitem{xie2020self}
Qizhe Xie, Minh-Thang Luong, Eduard Hovy, and Quoc~V Le.
\newblock Self-training with noisy student improves imagenet classification.
\newblock In {\em CVPR}, 2020.

\bibitem{xu2021seed}
Haohang Xu, Xiaopeng Zhang, Hao Li, Lingxi Xie, Hongkai Xiong, and Qi Tian.
\newblock Seed the views: Hierarchical semantic alignment for contrastive
  representation learning.
\newblock {\em arXiv preprint arXiv:2012.02733}, 2021.

\bibitem{xu2020iterative}
Qiantong Xu, Tatiana Likhomanenko, Jacob Kahn, Awni Hannun, Gabriel Synnaeve,
  and Ronan Collobert.
\newblock Iterative pseudo-labeling for speech recognition.
\newblock {\em preprint arXiv:2005.09267}, 2020.

\bibitem{yalniz2019billion}
I~Zeki Yalniz, Herv{\'e} J{\'e}gou, Kan Chen, Manohar Paluri, and Dhruv
  Mahajan.
\newblock Billion-scale semi-supervised learning for image classification.
\newblock {\em preprint arXiv:1905.00546}, 2019.

\bibitem{yang2016joint}
Jianwei Yang, Devi Parikh, and Dhruv Batra.
\newblock Joint unsupervised learning of deep representations and image
  clusters.
\newblock In {\em CVPR}, 2016.

\bibitem{zbontar2021barlow}
Jure Zbontar, Li Jing, Ishan Misra, Yann LeCun, and St{\'e}phane Deny.
\newblock Barlow twins: Self-supervised learning via redundancy reduction.
\newblock {\em arXiv preprint arXiv:2103.03230}, 2021.

\bibitem{zhang2016colorful}
Richard Zhang, Phillip Isola, and Alexei~A Efros.
\newblock Colorful image colorization.
\newblock In {\em ECCV}, 2016.

\bibitem{zhao2020exploring}
Hengshuang Zhao, Jiaya Jia, and Vladlen Koltun.
\newblock Exploring self-attention for image recognition.
\newblock In {\em CVPR}, 2020.

\bibitem{zhou2014learning}
Bolei Zhou, Agata Lapedriza, Jianxiong Xiao, Antonio Torralba, and Aude Oliva.
\newblock Learning deep features for scene recognition using places database.
\newblock In {\em NeurIPS}, 2014.

\bibitem{zhuang2019local}
Chengxu Zhuang, Alex~Lin Zhai, and Daniel Yamins.
\newblock Local aggregation for unsupervised learning of visual embeddings.
\newblock In {\em ICCV}, 2019.

\end{thebibliography}
