\begin{thebibliography}{42}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Asai et~al.(2019)Asai, Hashimoto, Hajishirzi, Socher, and
  Xiong]{rrp_salesforce}
Asai, A., Hashimoto, K., Hajishirzi, H., Socher, R., and Xiong, C.
\newblock Learning to retrieve reasoning paths over wikipedia graph for
  question answering.
\newblock \emph{arXiv preprint arXiv:1911.10470}, 2019.

\bibitem[Bahdanau et~al.(2014)Bahdanau, Cho, and Bengio]{attention}
Bahdanau, D., Cho, K., and Bengio, Y.
\newblock Neural machine translation by jointly learning to align and
  translate.
\newblock \emph{arXiv preprint arXiv:1409.0473}, 2014.

\bibitem[Berant et~al.(2013)Berant, Chou, Frostig, and Liang]{webquestions}
Berant, J., Chou, A., Frostig, R., and Liang, P.
\newblock Semantic parsing on freebase from question-answer pairs.
\newblock In \emph{Proceedings of the 2013 Conference on Empirical Methods in
  Natural Language Processing}, pp.\  1533--1544, 2013.

\bibitem[Brill et~al.(2002)Brill, Dumais, and Banko]{askmsr}
Brill, E., Dumais, S., and Banko, M.
\newblock An analysis of the askmsr question-answering system.
\newblock In \emph{Empirical Methods in Natural Language Processing}, 2002.

\bibitem[Chen et~al.(2017)Chen, Fisch, Weston, and Bordes]{drqa}
Chen, D., Fisch, A., Weston, J., and Bordes, A.
\newblock Reading wikipedia to answer open-domain questions.
\newblock In \emph{Proceedings of the 55th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, volume~1, pp.\
  1870--1879, 2017.

\bibitem[Clark \& Gardner(2017)Clark and Gardner]{bidaf_plusplus}
Clark, C. and Gardner, M.
\newblock Simple and effective multi-paragraph reading comprehension.
\newblock In \emph{Annual Meeting of the Association for Computational
  Linguistics}, 2017.

\bibitem[Dai \& Le(2015)Dai and Le]{dai_finetune}
Dai, A.~M. and Le, Q.~V.
\newblock Semi-supervised sequence learning.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  3079--3087, 2015.

\bibitem[Devlin et~al.(2018)Devlin, Chang, Lee, and Toutanova]{bert}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock \emph{arXiv preprint arXiv:1810.04805}, 2018.

\bibitem[Graves et~al.(2014)Graves, Wayne, and Danihelka]{neural_turing}
Graves, A., Wayne, G., and Danihelka, I.
\newblock Neural turing machines.
\newblock \emph{ArXiv}, abs/1410.5401, 2014.

\bibitem[Guu et~al.(2018)Guu, Hashimoto, Oren, and Liang]{prototypes}
Guu, K., Hashimoto, T.~B., Oren, Y., and Liang, P.
\newblock Generating sentences by editing prototypes.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  6:\penalty0 437--450, 2018.

\bibitem[Hashimoto et~al.(2018)Hashimoto, Guu, Oren, and
  Liang]{retrieve_and_edit}
Hashimoto, T.~B., Guu, K., Oren, Y., and Liang, P.~S.
\newblock A retrieve-and-edit framework for predicting structured outputs.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  10052--10062, 2018.

\bibitem[Joshi et~al.(2019)Joshi, Chen, Liu, Weld, Zettlemoyer, and
  Levy]{spanbert}
Joshi, M., Chen, D., Liu, Y., Weld, D.~S., Zettlemoyer, L., and Levy, O.
\newblock {SpanBERT}: Improving pre-training by representing and predicting
  spans.
\newblock \emph{arXiv preprint arXiv:1907.10529}, 2019.

\bibitem[Khandelwal et~al.(2019)Khandelwal, Levy, Jurafsky, Zettlemoyer, and
  Lewis]{knnlm}
Khandelwal, U., Levy, O., Jurafsky, D., Zettlemoyer, L., and Lewis, M.
\newblock Generalization through memorization: Nearest neighbor language
  models.
\newblock \emph{ArXiv}, abs/1911.00172, 2019.

\bibitem[Kiros et~al.(2015)Kiros, Zhu, Salakhutdinov, Zemel, Urtasun, Torralba,
  and Fidler]{skipthought}
Kiros, R., Zhu, Y., Salakhutdinov, R.~R., Zemel, R., Urtasun, R., Torralba, A.,
  and Fidler, S.
\newblock Skip-thought vectors.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  3294--3302, 2015.

\bibitem[Kwiatkowski et~al.(2019)Kwiatkowski, Palomaki, Rhinehart, Collins,
  Parikh, Alberti, Epstein, Polosukhin, Kelcey, Devlin,
  et~al.]{naturalquestions}
Kwiatkowski, T., Palomaki, J., Rhinehart, O., Collins, M., Parikh, A., Alberti,
  C., Epstein, D., Polosukhin, I., Kelcey, M., Devlin, J., et~al.
\newblock Natural questions: a benchmark for question answering research.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  2019.

\bibitem[Lample et~al.(2019)Lample, Sablayrolles, Ranzato, Denoyer, and
  J{\'e}gou]{product_key}
Lample, G., Sablayrolles, A., Ranzato, M., Denoyer, L., and J{\'e}gou, H.
\newblock Large memory layers with product keys.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  8546--8557, 2019.

\bibitem[Lee et~al.(2016)Lee, Salant, Kwiatkowski, Parikh, Das, and
  Berant]{rasor}
Lee, K., Salant, S., Kwiatkowski, T., Parikh, A., Das, D., and Berant, J.
\newblock Learning recurrent span representations for extractive question
  answering.
\newblock \emph{arXiv preprint arXiv:1611.01436}, 2016.

\bibitem[Lee et~al.(2019)Lee, Chang, and Toutanova]{orqa}
Lee, K., Chang, M.-W., and Toutanova, K.
\newblock Latent retrieval for weakly supervised open domain question
  answering.
\newblock In \emph{Proceedings of the Conference of Association for
  Computational Linguistics}, 2019.

\bibitem[Lewis et~al.(2019)Lewis, Liu, Goyal, Ghazvininejad, Mohamed, Levy,
  Stoyanov, and Zettlemoyer]{bart_not_bert}
Lewis, M., Liu, Y., Goyal, N., Ghazvininejad, M., Mohamed, A., Levy, O.,
  Stoyanov, V., and Zettlemoyer, L.
\newblock Bart: Denoising sequence-to-sequence pre-training for natural
  language generation, translation, and comprehension.
\newblock \emph{ArXiv}, abs/1910.13461, 2019.

\bibitem[Liu et~al.(2019)Liu, Ott, Goyal, Du, Joshi, Chen, Levy, Lewis,
  Zettlemoyer, and Stoyanov]{roberta}
Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M.,
  Zettlemoyer, L., and Stoyanov, V.
\newblock Roberta: A robustly optimized bert pretraining approach.
\newblock \emph{arXiv preprint arXiv:1907.11692}, 2019.

\bibitem[Mikolov et~al.(2013{\natexlab{a}})Mikolov, Chen, Corrado, and
  Dean]{skipgram}
Mikolov, T., Chen, K., Corrado, G., and Dean, J.
\newblock Efficient estimation of word representations in vector space.
\newblock \emph{arXiv preprint arXiv:1301.3781}, 2013{\natexlab{a}}.

\bibitem[Mikolov et~al.(2013{\natexlab{b}})Mikolov, Sutskever, Chen, Corrado,
  and Dean]{word2vec}
Mikolov, T., Sutskever, I., Chen, K., Corrado, G.~S., and Dean, J.
\newblock Distributed representations of words and phrases and their
  compositionality.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  3111--3119, 2013{\natexlab{b}}.

\bibitem[Miller et~al.(2016)Miller, Fisch, Dodge, Karimi, Bordes, and
  Weston]{key_value_memorynetwork}
Miller, A., Fisch, A., Dodge, J., Karimi, A.-H., Bordes, A., and Weston, J.
\newblock Key-value memory networks for directly reading documents.
\newblock \emph{arXiv preprint arXiv:1606.03126}, 2016.

\bibitem[Min et~al.(2019{\natexlab{a}})Min, Chen, Hajishirzi, and
  Zettlemoyer]{openqa_hardem}
Min, S., Chen, D., Hajishirzi, H., and Zettlemoyer, L.
\newblock A discrete hard em approach for weakly supervised question answering.
\newblock \emph{arXiv preprint arXiv:1909.04849}, 2019{\natexlab{a}}.

\bibitem[Min et~al.(2019{\natexlab{b}})Min, Chen, Zettlemoyer, and
  Hajishirzi]{GraphRetriever}
Min, S., Chen, D., Zettlemoyer, L., and Hajishirzi, H.
\newblock Knowledge guided text retrieval and reading for open domain question
  answering.
\newblock \emph{arXiv preprint arXiv:1911.03868}, 2019{\natexlab{b}}.

\bibitem[Peters et~al.(2018)Peters, Neumann, Iyyer, Gardner, Clark, Lee, and
  Zettlemoyer]{elmo}
Peters, M.~E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., and
  Zettlemoyer, L.
\newblock Deep contextualized word representations.
\newblock In \emph{Proc. of NAACL}, 2018.

\bibitem[Peters et~al.(2019)Peters, Neumann, IV, Schwartz, Joshi, Singh, and
  Smith]{knowbert}
Peters, M.~E., Neumann, M., IV, R. L.~L., Schwartz, R., Joshi, V., Singh, S.,
  and Smith, N.~A.
\newblock Knowledge enhanced contextual word representations, 2019.

\bibitem[Petroni et~al.(2019)Petroni, Rockt{\"a}schel, Lewis, Bakhtin, Wu,
  Miller, and Riedel]{lm_as_kb}
Petroni, F., Rockt{\"a}schel, T., Lewis, P., Bakhtin, A., Wu, Y., Miller,
  A.~H., and Riedel, S.
\newblock Language models as knowledge bases?
\newblock \emph{arXiv preprint arXiv:1909.01066}, 2019.

\bibitem[Radford et~al.(2018)Radford, Narasimhan, Salimans, and Sutskever]{gpt}
Radford, A., Narasimhan, K., Salimans, T., and Sutskever, I.
\newblock Improving language understanding with unsupervised learning.
\newblock Technical report, OpenAI, 2018.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, and
  Sutskever]{gpt2}
Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., and Sutskever, I.
\newblock Language models are unsupervised multitask learners.
\newblock \emph{OpenAI Blog}, 2019.

\bibitem[Raffel et~al.(2019)Raffel, Shazeer, Roberts, Lee, Narang, Matena,
  Zhou, Li, and Liu]{t5}
Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou,
  Y., Li, W., and Liu, P.~J.
\newblock Exploring the limits of transfer learning with a unified text-to-text
  transformer.
\newblock \emph{arXiv preprint arXiv:1910.10683}, 2019.

\bibitem[Rajpurkar et~al.(2016)Rajpurkar, Zhang, Lopyrev, and Liang]{squad}
Rajpurkar, P., Zhang, J., Lopyrev, K., and Liang, P.
\newblock Squad: 100,000+ questions for machine comprehension of text.
\newblock In \emph{Proceedings of the 2016 Conference on Empirical Methods in
  Natural Language Processing}, pp.\  2383--2392, 2016.

\bibitem[Rajpurkar et~al.(2018)Rajpurkar, Jia, and Liang]{squad2}
Rajpurkar, P., Jia, R., and Liang, P.
\newblock Know what you don't know: Unanswerable questions for squad.
\newblock \emph{arXiv preprint arXiv:1806.03822}, 2018.

\bibitem[Ram \& Gray(2012)Ram and Gray]{mips_cone}
Ram, P. and Gray, A.~G.
\newblock Maximum inner-product search using cone trees.
\newblock In \emph{Proceedings of the 18th ACM SIGKDD international conference
  on Knowledge discovery and data mining}, pp.\  931--939, 2012.

\bibitem[Roberts et~al.(2020)Roberts, Raffel, and Shazeer]{t5_openqa}
Roberts, A., Raffel, C., and Shazeer, N.
\newblock How much knowledge can you pack into the parameters of a language
  model?
\newblock \emph{arXiv preprint arXiv:TBD}, 2020.

\bibitem[Robertson et~al.(2009)Robertson, Zaragoza, et~al.]{bm25}
Robertson, S., Zaragoza, H., et~al.
\newblock The probabilistic relevance framework: Bm25 and beyond.
\newblock \emph{Foundations and Trends in Information Retrieval}, 3\penalty0
  (4):\penalty0 333--389, 2009.

\bibitem[Sang \& De~Meulder(2003)Sang and De~Meulder]{conll_ner}
Sang, E. T.~K. and De~Meulder, F.
\newblock Introduction to the conll-2003 shared task: Language-independent
  named entity recognition.
\newblock In \emph{Proceedings of the Seventh Conference on Natural Language
  Learning at HLT-NAACL 2003}, pp.\  142--147, 2003.

\bibitem[Seo et~al.(2016)Seo, Kembhavi, Farhadi, and Hajishirzi]{bidaf}
Seo, M., Kembhavi, A., Farhadi, A., and Hajishirzi, H.
\newblock Bidirectional attention flow for machine comprehension.
\newblock In \emph{International Conference on Learning Representations}, 2016.

\bibitem[Shen et~al.(2015)Shen, Liu, Zhang, Yang, and Tao~Shen]{mips_binary}
Shen, F., Liu, W., Zhang, S., Yang, Y., and Tao~Shen, H.
\newblock Learning binary codes for maximum inner product search.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pp.\  4148--4156, 2015.

\bibitem[Shrivastava \& Li(2014)Shrivastava and Li]{mips_alsh}
Shrivastava, A. and Li, P.
\newblock Asymmetric lsh (alsh) for sublinear time maximum inner product search
  (mips).
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  2321--2329, 2014.

\bibitem[Sukhbaatar et~al.(2015)Sukhbaatar, Weston, Fergus,
  et~al.]{end_to_end_memory}
Sukhbaatar, S., Weston, J., Fergus, R., et~al.
\newblock End-to-end memory networks.
\newblock In \emph{Advances in neural information processing systems}, 2015.

\bibitem[Weston et~al.(2014)Weston, Chopra, and Bordes]{memory_networks}
Weston, J., Chopra, S., and Bordes, A.
\newblock Memory networks.
\newblock \emph{arXiv preprint arXiv:1410.3916}, 2014.

\end{thebibliography}
